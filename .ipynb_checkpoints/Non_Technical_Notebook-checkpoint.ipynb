{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**: The goal of this notebook is to create a machine learning model to accurately predict cases of car insurance fraud and to understand what characterisitcs in a claim are most indicative of potential fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: https://www.kaggle.com/roshansharma/insurance-claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub: https://github.com/ArielJosephCohen/capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentation: https://docs.google.com/presentation/d/1IQdYSxrzyGvMpurhM-i097Btp4ksqL70WLEiM6yc5Sw/edit#slide=id.g35f391192_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will save some stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid messages for warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load helper module with custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import custom backend code and functions\n",
    "import helper_module as hm\n",
    "from helper_module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load central data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load primary data\n",
    "df = pd.read_csv('Claims.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign uniform randomness for entire project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a random state to be used throughout notebook\n",
    "seed = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address '?' values in data\n",
    "df = hm.clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for policy bind year and month\n",
    "df = hm.reassign_year_and_month(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a car type to auto models\n",
    "auto_model_dict = hm.create_auto_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map car type\n",
    "df.auto_model = df.auto_model.map(lambda x: auto_model_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a timeline between policy bind data and claim\n",
    "df = hm.create_timeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that I have the timeline and month-year information, I can drop some more columns\n",
    "df.drop(['incident_date','policy_bind_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show capital loss as a positive value\n",
    "df = hm.quantify_absolute_value(df,'capital-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign numerical binary to insured sex\n",
    "df = hm.map_binary_dict(df,'insured_sex','MALE','FEMALE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign numerical binary to fraud reported (target feature)\n",
    "df = hm.map_binary_dict(df,'fraud_reported','Y','N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate lists of numerical and categorical features\n",
    "num_list = hm.create_num_list()\n",
    "cat_list = hm.create_cat_list()\n",
    "cat_list_2 = hm.create_cat_list_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlated features and update numerical feature list\n",
    "df,num_list = hm.remove_correlation(df,num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categorical and numerical data frames\n",
    "df_num = df[num_list]\n",
    "df_cat = df[cat_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical data as numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use correlation with target variable to encode categorical features\n",
    "for col in cat_list_2:\n",
    "    df_cat = create_encoding(col,df_cat,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data frames and revisit correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge categorical and numerical data frames into one\n",
    "df_atg = hm.combine_data_frames(df_cat,df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlation from encoded categorical features\n",
    "df_atg = hm.remove_categorical_correlation(df_atg,'incident_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce un-needed features\n",
    "x_and_y = hm.reduce_features(df_atg,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter, normalize, and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter outliers\n",
    "x_and_y = hm.filter_outliers(x_and_y,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X = x_and_y.drop('fraud_reported',axis=1)\n",
    "y = x_and_y.fraud_reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "X = hm.normalize_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features\n",
    "X = hm.min_max_scale_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train set and validation set\n",
    "X_train, X_test, y_train, y_test = hm.split_data(X,y,seed,t_s=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance data for more meaningful results\n",
    "X_train, y_train = hm.upsample_data(X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression score\n",
    "lr_train_scores,lr_train_class_rep,lr_train_cm = hm.models.logistic_regression_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine scores\n",
    "svc_train_scores,svc_train_class_rep,svc_train_cm = hm.models.support_vector_machine_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k nearest neighbors score\n",
    "knn_train_scores,knn_train_class_rep,knn_train_cm = hm.models.knn_model(X_train,y_train,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian naive bayes score\n",
    "gnb_train_scores,gnb_train_class_rep,gnb_train_cm = hm.models.gaussian_naive_bayes_model(X_train,y_train,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear svc score\n",
    "lsvc_train_scores,lsvc_train_class_rep,lsvc_train_cm = hm.models.linear_svc_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic gradient descent score\n",
    "sgd_train_scores,sgd_train_class_rep,sgd_train_cm = hm.models.stochastic_gradient_descent_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree score\n",
    "dt_train_scores,dt_train_class_rep,dt_train_cm = hm.models.decision_tree_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest score\n",
    "rf_train_scores,rf_train_class_rep,rf_train_cm = hm.models.random_forest_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost score\n",
    "xgb_train_scores,xgb_train_class_rep,xgb_train_cm = hm.models.XGBoost_model(X_train,y_train,X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train validation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary data frame\n",
    "train_summary = pd.DataFrame(hm.models.metrics_train).set_index('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression validation score\n",
    "lr_test_scores,lr_test_class_rep,lr_test_cm = hm.models.logistic_regression_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine validation score\n",
    "svc_test_scores,svc_test_class_rep,svc_test_cm = hm.models.support_vector_machine_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k nearest neighbors validation score\n",
    "knn_test_scores,knn_test_class_rep,knn_test_cm = hm.models.knn_model(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian naive bayes validation score\n",
    "gnb_test_scores,gnb_test_class_rep,gnb_test_cm = hm.models.gaussian_naive_bayes_model(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear svc validation score\n",
    "lsvc_test_scores,lsvc_test_class_rep,lsvc_test_cm = hm.models.linear_svc_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic gradient descent validation score\n",
    "sgd_test_scores,sgd_test_class_rep,sgd_test_cm = hm.models.stochastic_gradient_descent_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree validation score\n",
    "dt_test_scores,dt_test_class_rep,dt_test_cm = hm.models.decision_tree_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest validation score\n",
    "rf_test_scores,rf_test_class_rep,rf_test_cm = hm.models.random_forest_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost validation score\n",
    "xgb_test_scores,xgb_test_class_rep,xgb_test_cm = hm.models.XGBoost_model(X_train,y_train,X_test,y_test,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test validation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary data frame\n",
    "test_summary = pd.DataFrame(hm.models.metrics_test).set_index('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakdown of most indicative features\n",
    "important_features = hm.find_feature_importance(X_train,y_train,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual of how decision tree operates\n",
    "decision_tree_visual = hm.draw_decision_tree(seed,X_train,y_train,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
